<html>
<head>
	<title>Fundementals Part 1 </title>
</head>
<body>
	<script>
		// 1. Create a program that goes through each value in array x, where x is [3,5,'Dojo', 'rocks', {name: 'Michael', title: 'Sensei'}]. Have it display each value of the array as well as the type of each value. For example, it should say or log "3: 'number', 5: 'number', 'rocks': 'string', ...".
		var x = [3,5,'Dojo', 'rocks', {name: 'Michael', title: 'Sensei'}];
		for(var i = 0; i < x.length; i++) {
			console.log(x[i]+': '+typeof(x[i]));
		}

		// 2. Add a new value in the array x using a push method. New value you should add is 100.
		x.push(100);

		// 3. Add a new array as the last member of the array then log x in the console and analyze how x looks.
		x.push([3,2,1]);
		console.log(x);

		// 4. Create a simple for loop that sums all the numbers between 1 to 500. Have console log the final sum.
		var sum = 0;
		for (var i = 1; i <= 500; i++) {
			sum += i;
		}
		console.log(sum);

		// 5. Create another simple for loop that sums all the numbers between 1 to 1 million. Now, we want you to figure out how long in milliseconds this operation takes. Study http://www.w3schools.com/jsref/jsref_gettime.asp to learn more about how you can get the time in milliseconds. You can basically get the time of the operation by getting this timestamp before you start the for loop and getting another timestamp after the for loop is over. By subtracting the two timestamps, you can obtain how long this operation took.
		var start = new Date().getTime();
		// var start = window.performance.now(); // This was something I read about when reseaching, it is supposedly more correct.
		var sum = 0;
		for (var i = 1; i <= 1000000; i++) {
			sum += i;
		}
		var end = new Date().getTime();
		// var end = window.performance.now();  // This was something I read about when reseaching, it is supposedly more correct.
		var time = end-start;
		console.log(time);
		
	</script>

</body>
</html>